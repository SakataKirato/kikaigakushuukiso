{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "editable": false,
    "id": "w0miHB_4j6fO",
    "outputId": "2b8535a0-4018-4af3-c73c-e0f06916eba3",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install schedulefree -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2024-10-31T16:06:35.009259Z",
     "iopub.status.busy": "2024-10-31T16:06:35.008896Z",
     "iopub.status.idle": "2024-10-31T16:06:35.040481Z",
     "shell.execute_reply": "2024-10-31T16:06:35.039428Z",
     "shell.execute_reply.started": "2024-10-31T16:06:35.009221Z"
    },
    "id": "wmcUA-Kyj6fR",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"/kaggle/input/eds-232-ocean-chemistry-prediction-for-calcofi/train.csv\")\n",
    "test=pd.read_csv(\"/kaggle/input/eds-232-ocean-chemistry-prediction-for-calcofi/test.csv\")\n",
    "sub=pd.read_csv(\"/kaggle/input/eds-232-ocean-chemistry-prediction-for-calcofi/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2024-10-31T16:06:35.160063Z",
     "iopub.status.busy": "2024-10-31T16:06:35.159559Z",
     "iopub.status.idle": "2024-10-31T16:06:38.637873Z",
     "shell.execute_reply": "2024-10-31T16:06:38.636808Z",
     "shell.execute_reply.started": "2024-10-31T16:06:35.160004Z"
    },
    "id": "2SYojsJUj6fS",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, PolynomialFeatures, PowerTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Drop unneeded columns and handle missing values\n",
    "train = train.drop(columns=[\"Unnamed: 12\", \"id\"])  # Dropping unnecessary columns\n",
    "\n",
    "# CRITICAL FIX: Rename TA1.x to TA1 to match test data\n",
    "train = train.rename(columns={\"TA1.x\": \"TA1\"})\n",
    "\n",
    "# ============================================\n",
    "# Extract Raw Features and Target\n",
    "# ============================================\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"DATA PREPARATION\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Extract features and target\n",
    "feature_columns = [col for col in train.columns if col != 'DIC']\n",
    "X_raw = train[feature_columns].copy()\n",
    "y_raw = train['DIC'].values.copy()\n",
    "X_test_raw = test[feature_columns].copy()\n",
    "\n",
    "print(f\"元の訓練データ: {X_raw.shape}\")\n",
    "print(f\"テストデータ: {X_test_raw.shape}\")\n",
    "\n",
    "# ============================================\n",
    "# Holdout Validation Setup\n",
    "# ============================================\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"HOLDOUT VALIDATION SETUP\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# 80% train, 20% validation\n",
    "X_train_raw, X_val_raw, y_train_raw, y_val_raw = train_test_split(\n",
    "    X_raw, y_raw, test_size=0.2, random_state=SEED\n",
    ")\n",
    "\n",
    "print(f\"Train set: {X_train_raw.shape[0]} samples\")\n",
    "print(f\"Validation set: {X_val_raw.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test_raw.shape[0]} samples\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2024-10-31T16:06:38.679793Z",
     "iopub.status.busy": "2024-10-31T16:06:38.679208Z",
     "iopub.status.idle": "2024-10-31T16:06:38.702210Z",
     "shell.execute_reply": "2024-10-31T16:06:38.701153Z",
     "shell.execute_reply.started": "2024-10-31T16:06:38.679681Z"
    },
    "id": "8kUw3FU7j6fT",
    "outputId": "a9af3f6d-335d-4a85-c2c1-bf760562a6b5",
    "trusted": true
   },
   "outputs": [],
   "source": "# ============================================\n# ResNet Model for Tabular Data\n# Based on \"Revisiting Deep Learning Models for Tabular Data\" (NeurIPS 2021)\n# Unified structure that can optionally use DAE pretrained weights\n# ============================================\n\nclass ResNetBlock(nn.Module):\n    \"\"\"\n    ResNet Block for tabular data\n    ResNetBlock(x) = x + Dropout(Linear(Dropout(ReLU(Linear(BatchNorm(x))))))\n    \"\"\"\n    def __init__(self, d, hidden_factor=2, dropout_rate=0.1):\n        \"\"\"\n        Args:\n            d: Dimension of input and output\n            hidden_factor: Factor to determine hidden layer size (hidden = d * hidden_factor)\n            dropout_rate: Dropout probability\n        \"\"\"\n        super(ResNetBlock, self).__init__()\n        \n        hidden_dim = int(d * hidden_factor)\n        \n        self.norm = nn.BatchNorm1d(d)\n        self.linear1 = nn.Linear(d, hidden_dim)\n        self.relu = nn.ReLU()\n        self.dropout1 = nn.Dropout(dropout_rate)\n        self.linear2 = nn.Linear(hidden_dim, d)\n        self.dropout2 = nn.Dropout(dropout_rate)\n        \n        # Initialize weights\n        nn.init.kaiming_normal_(self.linear1.weight, mode='fan_in', nonlinearity='relu')\n        nn.init.kaiming_normal_(self.linear2.weight, mode='fan_in', nonlinearity='relu')\n        nn.init.constant_(self.linear1.bias, 0)\n        nn.init.constant_(self.linear2.bias, 0)\n    \n    def forward(self, x):\n        # Main path: BatchNorm -> Linear -> ReLU -> Dropout -> Linear -> Dropout\n        residual = x\n        x = self.norm(x)\n        x = self.linear1(x)\n        x = self.relu(x)\n        x = self.dropout1(x)\n        x = self.linear2(x)\n        x = self.dropout2(x)\n        \n        # Residual connection\n        return residual + x\n\n\nclass ResNetModel(nn.Module):\n    \"\"\"\n    Unified ResNet for tabular data that can optionally load DAE pretrained encoder\n    Always has the same structure: input_layer + encoder_blocks + additional_blocks + prediction_head\n    \"\"\"\n    def __init__(self, input_size, d=256, n_encoder_blocks=4, n_additional_blocks=0, \n                 hidden_factor=2, dropout_rate=0.1):\n        \"\"\"\n        Args:\n            input_size: Number of input features\n            d: Dimension of ResNet blocks\n            n_encoder_blocks: Number of encoder blocks (can be loaded from DAE)\n            n_additional_blocks: Number of additional blocks after encoder\n            hidden_factor: Hidden layer factor for each block\n            dropout_rate: Dropout probability\n        \"\"\"\n        super(ResNetModel, self).__init__()\n        \n        self.n_encoder_blocks = n_encoder_blocks\n        self.n_additional_blocks = n_additional_blocks\n        \n        # Initial projection (part of encoder)\n        self.input_layer = nn.Linear(input_size, d)\n        nn.init.kaiming_normal_(self.input_layer.weight, mode='fan_in', nonlinearity='relu')\n        nn.init.constant_(self.input_layer.bias, 0)\n        \n        # Encoder blocks (can be loaded from pretrained DAE)\n        self.encoder_blocks = nn.ModuleList([\n            ResNetBlock(d, hidden_factor, dropout_rate) \n            for _ in range(n_encoder_blocks)\n        ])\n        \n        # Encoder normalization (part of encoder, can be loaded from DAE)\n        self.encoder_norm = nn.BatchNorm1d(d)\n        self.encoder_relu = nn.ReLU()\n        \n        # Additional blocks (always randomly initialized)\n        if n_additional_blocks > 0:\n            self.additional_blocks = nn.ModuleList([\n                ResNetBlock(d, hidden_factor, dropout_rate) \n                for _ in range(n_additional_blocks)\n            ])\n        else:\n            self.additional_blocks = None\n        \n        # Prediction head\n        self.final_norm = nn.BatchNorm1d(d)\n        self.final_relu = nn.ReLU()\n        self.output = nn.Linear(d, 1)\n        nn.init.xavier_normal_(self.output.weight)\n        nn.init.constant_(self.output.bias, 0)\n    \n    def load_dae_encoder_weights(self, dae_state_dict, freeze_encoder=False):\n        \"\"\"\n        Load pretrained DAE encoder weights into this model's encoder\n        \n        Args:\n            dae_state_dict: State dict from pretrained DenoisingAutoencoder\n            freeze_encoder: If True, freeze encoder parameters\n        \"\"\"\n        # Mapping from DAE encoder keys to ResNet encoder keys\n        # DAE: encoder.input_layer -> ResNet: input_layer\n        # DAE: encoder.blocks.0.* -> ResNet: encoder_blocks.0.*\n        # DAE: encoder.final_norm -> ResNet: encoder_norm\n        # DAE: encoder.final_relu -> ResNet: encoder_relu (no parameters, skip)\n        \n        encoder_state_dict = {}\n        \n        for key, value in dae_state_dict.items():\n            if key.startswith('encoder.'):\n                # Remove 'encoder.' prefix\n                new_key = key.replace('encoder.', '')\n                \n                # Rename 'blocks' to 'encoder_blocks'\n                if new_key.startswith('blocks.'):\n                    new_key = new_key.replace('blocks.', 'encoder_blocks.')\n                \n                # Rename 'final_norm' to 'encoder_norm'\n                if new_key.startswith('final_norm.'):\n                    new_key = new_key.replace('final_norm.', 'encoder_norm.')\n                \n                encoder_state_dict[new_key] = value\n        \n        # Load weights (strict=False because we're only loading encoder part)\n        missing_keys, unexpected_keys = self.load_state_dict(encoder_state_dict, strict=False)\n        \n        # Verify that encoder parts were loaded\n        expected_encoder_keys = [\n            'input_layer.weight', 'input_layer.bias',\n            'encoder_norm.weight', 'encoder_norm.bias'\n        ]\n        for i in range(self.n_encoder_blocks):\n            expected_encoder_keys.extend([\n                f'encoder_blocks.{i}.norm.weight',\n                f'encoder_blocks.{i}.norm.bias',\n                f'encoder_blocks.{i}.linear1.weight',\n                f'encoder_blocks.{i}.linear1.bias',\n                f'encoder_blocks.{i}.linear2.weight',\n                f'encoder_blocks.{i}.linear2.bias',\n            ])\n        \n        loaded_encoder_keys = set(encoder_state_dict.keys())\n        expected_set = set(expected_encoder_keys)\n        \n        if not expected_set.issubset(loaded_encoder_keys):\n            missing = expected_set - loaded_encoder_keys\n            print(f\"Warning: Some encoder keys were not loaded: {missing}\")\n        \n        # Optionally freeze encoder\n        if freeze_encoder:\n            self.input_layer.requires_grad_(False)\n            for block in self.encoder_blocks:\n                block.requires_grad_(False)\n            self.encoder_norm.requires_grad_(False)\n        \n        return len(encoder_state_dict)\n    \n    def forward(self, x):\n        # Initial projection\n        x = self.input_layer(x)\n        \n        # Encoder blocks\n        for block in self.encoder_blocks:\n            x = block(x)\n        \n        # Encoder normalization\n        x = self.encoder_norm(x)\n        x = self.encoder_relu(x)\n        \n        # Additional blocks (if any)\n        if self.additional_blocks is not None:\n            for block in self.additional_blocks:\n                x = block(x)\n        \n        # Prediction head\n        x = self.final_norm(x)\n        x = self.final_relu(x)\n        x = self.output(x)\n        \n        return x\n\n\n# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"\\n{'='*60}\")\nprint(f\"Using device: {device}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\nprint(f\"{'='*60}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================\n# Denoising Autoencoder (DAE) for Tabular Data\n# ResNetBlockベースの構造で統一\n# ============================================\n\nclass DAEEncoder(nn.Module):\n    \"\"\"\n    DAE Encoder using ResNetBlock structure\n    ResNetModelのencoder部分と完全に同じ構造\n    \"\"\"\n    def __init__(self, input_size, d, n_blocks, hidden_factor=2, dropout_rate=0.1):\n        \"\"\"\n        Args:\n            input_size: Number of input features\n            d: Dimension of ResNet blocks\n            n_blocks: Number of ResNet blocks\n            hidden_factor: Hidden layer factor for each block\n            dropout_rate: Dropout probability\n        \"\"\"\n        super(DAEEncoder, self).__init__()\n        \n        # Initial projection (ResNetModelと同じ)\n        self.input_layer = nn.Linear(input_size, d)\n        nn.init.kaiming_normal_(self.input_layer.weight, mode='fan_in', nonlinearity='relu')\n        nn.init.constant_(self.input_layer.bias, 0)\n        \n        # ResNet blocks (ResNetModelと完全に同じ構造)\n        self.blocks = nn.ModuleList([\n            ResNetBlock(d, hidden_factor, dropout_rate) \n            for _ in range(n_blocks)\n        ])\n        \n        # Final normalization (ResNetModelのencoder_normと同じ)\n        self.final_norm = nn.BatchNorm1d(d)\n        self.final_relu = nn.ReLU()\n    \n    def forward(self, x):\n        # Initial projection\n        x = self.input_layer(x)\n        \n        # Pass through ResNet blocks\n        for block in self.blocks:\n            x = block(x)\n        \n        # Final normalization\n        x = self.final_norm(x)\n        x = self.final_relu(x)\n        \n        return x\n\n\nclass DAEDecoder(nn.Module):\n    \"\"\"\n    DAE Decoder to reconstruct input from latent representation\n    \"\"\"\n    def __init__(self, d, output_size):\n        \"\"\"\n        Args:\n            d: Dimension of latent representation\n            output_size: Number of output features (same as input)\n        \"\"\"\n        super(DAEDecoder, self).__init__()\n        \n        # Simple decoder: Linear projection back to input space\n        self.output_layer = nn.Linear(d, output_size)\n        nn.init.xavier_normal_(self.output_layer.weight)\n        nn.init.constant_(self.output_layer.bias, 0)\n    \n    def forward(self, x):\n        return self.output_layer(x)\n\n\nclass DenoisingAutoencoder(nn.Module):\n    \"\"\"\n    Denoising Autoencoder with ResNetBlock-based encoder\n    エンコーダーがResNetModelのencoder部分と完全に同じ構造\n    \"\"\"\n    def __init__(self, input_size, d=256, n_blocks=4, hidden_factor=2, dropout_rate=0.1):\n        \"\"\"\n        Args:\n            input_size: Number of input features\n            d: Dimension of ResNet blocks\n            n_blocks: Number of ResNet blocks\n            hidden_factor: Hidden layer factor for each block\n            dropout_rate: Dropout probability\n        \"\"\"\n        super(DenoisingAutoencoder, self).__init__()\n        \n        self.encoder = DAEEncoder(input_size, d, n_blocks, hidden_factor, dropout_rate)\n        self.decoder = DAEDecoder(d, input_size)\n    \n    def forward(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded\n    \n    def encode(self, x):\n        \"\"\"Run only the encoder part\"\"\"\n        return self.encoder(x)\n\n\ndef add_noise(x, noise_type='gaussian', noise_level=0.1):\n    \"\"\"\n    Add noise to input data\n    \n    Args:\n        x: Input data (torch tensor)\n        noise_type: 'gaussian', 'masking', or 'swap'\n        noise_level: Noise strength\n    \"\"\"\n    if noise_type == 'gaussian':\n        # Gaussian noise\n        noise = torch.randn_like(x) * noise_level\n        return x + noise\n    \n    elif noise_type == 'masking':\n        # Random masking (set some features to zero)\n        mask = torch.rand_like(x) > noise_level\n        return x * mask.float()\n    \n    elif noise_type == 'swap':\n        # Swap noise (randomly swap values)\n        noisy_x = x.clone()\n        for i in range(x.shape[1]):\n            if torch.rand(1).item() < noise_level:\n                # Shuffle this feature\n                idx = torch.randperm(x.shape[0])\n                noisy_x[:, i] = x[idx, i]\n        return noisy_x\n    \n    else:\n        raise ValueError(f\"Unknown noise type: {noise_type}\")\n\n\ndef pretrain_dae(dae, X_train, X_val, epochs=100, batch_size=64, \n                 noise_type='gaussian', noise_level=0.1, \n                 learning_rate=1e-3, patience=20, device='cuda', seed=42, verbose=False):\n    \"\"\"\n    Pretrain DAE with reconstruction objective\n    \n    Returns:\n        best_dae_state: Best model state\n        best_val_loss: Best validation loss\n    \"\"\"\n    # Set random seeds\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    \n    dae = dae.to(device)\n    criterion = nn.MSELoss()\n    optimizer = optim.AdamW(dae.parameters(), lr=learning_rate, weight_decay=1e-5)\n    \n    # Create DataLoaders with explicit generator\n    g = torch.Generator()\n    g.manual_seed(seed)\n    \n    train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32))\n    val_dataset = TensorDataset(torch.tensor(X_val, dtype=torch.float32))\n    \n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, generator=g)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n    \n    best_val_loss = float('inf')\n    best_dae_state = None\n    patience_counter = 0\n    \n    use_amp = torch.cuda.is_available()\n    scaler = GradScaler('cuda') if use_amp else None\n    \n    for epoch in range(epochs):\n        # Training\n        dae.train()\n        train_loss = 0\n        for (X_batch,) in train_loader:\n            X_batch = X_batch.to(device)\n            \n            # Add noise\n            X_noisy = add_noise(X_batch, noise_type=noise_type, noise_level=noise_level)\n            \n            # Reconstruct\n            optimizer.zero_grad()\n            \n            if use_amp:\n                with autocast('cuda'):\n                    X_reconstructed = dae(X_noisy)\n                    loss = criterion(X_reconstructed, X_batch)  # Reconstruct original data\n                \n                scaler.scale(loss).backward()\n                scaler.step(optimizer)\n                scaler.update()\n            else:\n                X_reconstructed = dae(X_noisy)\n                loss = criterion(X_reconstructed, X_batch)\n                loss.backward()\n                optimizer.step()\n            \n            train_loss += loss.item() * X_batch.size(0)\n        \n        train_loss /= len(train_dataset)\n        \n        # Validation\n        dae.eval()\n        val_loss = 0\n        with torch.no_grad():\n            for (X_batch,) in val_loader:\n                X_batch = X_batch.to(device)\n                X_noisy = add_noise(X_batch, noise_type=noise_type, noise_level=noise_level)\n                \n                if use_amp:\n                    with autocast('cuda'):\n                        X_reconstructed = dae(X_noisy)\n                        loss = criterion(X_reconstructed, X_batch)\n                else:\n                    X_reconstructed = dae(X_noisy)\n                    loss = criterion(X_reconstructed, X_batch)\n                \n                val_loss += loss.item() * X_batch.size(0)\n        \n        val_loss /= len(val_dataset)\n        \n        # Early stopping\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            best_dae_state = copy.deepcopy(dae.state_dict())\n            patience_counter = 0\n        else:\n            patience_counter += 1\n        \n        if verbose and (epoch + 1) % 10 == 0:\n            print(f\"  DAE Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}\")\n        \n        if patience_counter >= patience:\n            if verbose:\n                print(f\"  DAE early stopping at epoch {epoch+1}\")\n            break\n    \n    return best_dae_state, best_val_loss\n\nprint(\"DAE classes and functions loaded successfully (Unified structure with ResNetModel)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import torch.optim as optim\nfrom schedulefree import RAdamScheduleFree, AdamWScheduleFree\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\nfrom torch.amp import autocast, GradScaler\nfrom sklearn.preprocessing import RobustScaler\nimport copy\n\n# ============================================\n# Configuration\n# ============================================\nSEED = 42\n\n# Fixed settings\nuse_c_mixup = True\nc_mixup_alpha = 1.0\nc_mixup_sigma = 1.0\nc_mixup_factor = 2\nepochs = 100000\nearly_stopping_patience = 500\n\n# DAE settings\ndae_pretrain_epochs = 200\ndae_patience = 30\n\nprint(\"=\"*60)\nprint(\"ResNet for Tabular Data with Unified Architecture\")\nprint(\"=\"*60)\nprint(f\"SEED: {SEED}\")\nprint(f\"epochs: {epochs}\")\nprint(f\"early_stopping_patience: {early_stopping_patience}\")\nprint(f\"dae_pretrain_epochs: {dae_pretrain_epochs}\")\nprint(\"=\"*60)\n\n\nclass EMA:\n    \"\"\"Exponential Moving Average (EMA) for model weights\"\"\"\n    def __init__(self, model, decay=0.999):\n        self.model = model\n        self.decay = decay\n        self.shadow = {}\n        self.backup = {}\n        self.register()\n    \n    def register(self):\n        for name, param in self.model.named_parameters():\n            if param.requires_grad:\n                self.shadow[name] = param.data.clone()\n    \n    def update(self):\n        for name, param in self.model.named_parameters():\n            if param.requires_grad:\n                new_average = self.decay * self.shadow[name] + (1.0 - self.decay) * param.data\n                self.shadow[name] = new_average.clone()\n    \n    def apply_shadow(self):\n        for name, param in self.model.named_parameters():\n            if param.requires_grad:\n                self.backup[name] = param.data.clone()\n                param.data = self.shadow[name]\n    \n    def restore(self):\n        for name, param in self.model.named_parameters():\n            if param.requires_grad:\n                param.data = self.backup[name]\n        self.backup = {}\n\n\ndef smooth_clip(x, clip_val=3.0):\n    \"\"\"Apply smooth clipping using tanh\"\"\"\n    return np.tanh(x / clip_val) * clip_val\n\n\ndef inverse_smooth_clip(x, clip_val=3.0):\n    \"\"\"Inverse of smooth clipping with numerical stability\"\"\"\n    x_normalized = x / clip_val\n    x_safe = np.clip(x_normalized, -0.995, 0.995)\n    result = np.arctanh(x_safe) * clip_val\n    result = np.where(np.isfinite(result), result, np.sign(x) * clip_val * 10)\n    return result\n\n\ndef c_mixup(X, y, alpha=1.0, sigma=1.0, augment_factor=2):\n    \"\"\"C-Mixup (Calibrated Mixup) data augmentation\"\"\"\n    n_samples = X.shape[0]\n    \n    y_expanded = y.reshape(-1, 1)\n    label_distances = (y_expanded - y_expanded.T) ** 2\n    \n    sampling_probs = np.exp(-label_distances / (2 * sigma ** 2))\n    np.fill_diagonal(sampling_probs, 0)\n    row_sums = sampling_probs.sum(axis=1, keepdims=True)\n    row_sums[row_sums == 0] = 1\n    sampling_probs = sampling_probs / row_sums\n    \n    X_augmented = []\n    y_augmented = []\n    \n    for _ in range(augment_factor):\n        for i in range(n_samples):\n            j = np.random.choice(n_samples, p=sampling_probs[i])\n            lambda_mix = np.random.beta(alpha, alpha)\n            \n            x_mix = lambda_mix * X[i] + (1 - lambda_mix) * X[j]\n            y_mix = lambda_mix * y[i] + (1 - lambda_mix) * y[j]\n            \n            X_augmented.append(x_mix)\n            y_augmented.append(y_mix)\n    \n    X_aug = np.vstack([X] + [np.array(X_augmented)])\n    y_aug = np.hstack([y] + [np.array(y_augmented)])\n    \n    return X_aug, y_aug\n\n\n# ============================================\n# Hyperparameters (Unified Architecture)\n# ============================================\nparams = {\n    # DAE settings\n    'use_dae': True,                    # DAE事前学習を使用するか\n    'dae_noise_type': 'gaussian',       # ノイズタイプ: 'gaussian', 'masking', 'swap'\n    'dae_noise_level': 0.1,             # ノイズの強さ\n    'dae_lr': 1e-3,                     # DAE事前学習の学習率\n    'freeze_dae': False,                # DAEエンコーダーを固定するか\n    \n    # Model architecture (統一構造)\n    'd': 256,                           # モデルの次元数\n    'n_blocks': 4,                      # エンコーダーブロック数（DAE事前学習対象）\n    'n_additional_blocks': 2,           # エンコーダー後の追加ブロック数\n    'hidden_factor': 2.0,               # 隠れ層の倍率\n    'dropout_rate': 0.1,                # Dropout率（全ブロック共通）\n    \n    # Training\n    'learning_rate': 1e-4,\n    'weight_decay': 1e-5,\n    'batch_size': 64,\n    'optimizer': 'adamw_schedulefree',  # 'adamw', 'adamw_schedulefree', 'radam_schedulefree'\n    'loss_function': 'mae',             # 'mse', 'mae', 'smooth_l1', 'huber'\n    \n    # EMA\n    'use_ema': True,\n    'ema_decay': 0.999,\n}\n\nprint(\"\\nHyperparameters:\")\nfor key, value in params.items():\n    print(f\"  {key}: {value}\")\nprint()\n\ntotal_blocks = params['n_blocks'] + params['n_additional_blocks']\nprint(f\"Model structure (Unified):\")\nprint(f\"  Encoder blocks: {params['n_blocks']} blocks {'(can load DAE pretrained weights)' if params['use_dae'] else ''}\")\nprint(f\"  Additional blocks: {params['n_additional_blocks']} blocks (always randomly initialized)\")\nprint(f\"  Total: {total_blocks} ResNet blocks\")\nprint()\n\n\n# ============================================\n# Set random seeds\n# ============================================\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\n\n# ============================================\n# Preprocessing\n# ============================================\nprint(\"\\n\" + \"=\"*60)\nprint(\"PREPROCESSING\")\nprint(\"=\"*60)\n\nscaler_X = RobustScaler()\nscaler_y = RobustScaler()\n\nX_train_scaled = scaler_X.fit_transform(X_train_raw.values)\nX_val_scaled = scaler_X.transform(X_val_raw.values)\nX_test_scaled = scaler_X.transform(X_test_raw.values)\n\ny_train_scaled = scaler_y.fit_transform(y_train_raw.reshape(-1, 1)).flatten()\ny_val_scaled = scaler_y.transform(y_val_raw.reshape(-1, 1)).flatten()\n\n# Smooth Clipping\nclip_val = 3.0\nX_train_clipped = smooth_clip(X_train_scaled, clip_val=clip_val)\nX_val_clipped = smooth_clip(X_val_scaled, clip_val=clip_val)\nX_test_clipped = smooth_clip(X_test_scaled, clip_val=clip_val)\ny_train_clipped = smooth_clip(y_train_scaled, clip_val=clip_val)\ny_val_clipped = smooth_clip(y_val_scaled, clip_val=clip_val)\n\nprint(\"Preprocessing complete\")\n\n\n# ============================================\n# DAE Pretraining (if enabled)\n# ============================================\ndae_state = None\nif params['use_dae']:\n    print(\"\\n\" + \"=\"*60)\n    print(\"DAE PRETRAINING\")\n    print(\"=\"*60)\n    \n    # DAEの初期化（ResNetModelのエンコーダー部分と同じ構造）\n    dae = DenoisingAutoencoder(\n        input_size=X_train_clipped.shape[1],\n        d=params['d'],\n        n_blocks=params['n_blocks'],\n        hidden_factor=params['hidden_factor'],\n        dropout_rate=params['dropout_rate']\n    )\n    \n    print(f\"DAE structure: {params['n_blocks']} ResNet blocks, d={params['d']}\")\n    print(f\"This matches ResNetModel encoder structure\")\n    \n    dae_state, dae_val_loss = pretrain_dae(\n        dae,\n        X_train_clipped,\n        X_val_clipped,\n        epochs=dae_pretrain_epochs,\n        batch_size=params['batch_size'],\n        noise_type=params['dae_noise_type'],\n        noise_level=params['dae_noise_level'],\n        learning_rate=params['dae_lr'],\n        patience=dae_patience,\n        device=device,\n        seed=SEED,\n        verbose=True\n    )\n    \n    print(f\"\\nDAE pretraining complete. Best Val Loss: {dae_val_loss:.6f}\")\n\n\n# ============================================\n# C-Mixup augmentation\n# ============================================\nprint(\"\\n\" + \"=\"*60)\nprint(\"DATA AUGMENTATION\")\nprint(\"=\"*60)\n\nif use_c_mixup:\n    X_train_final, y_train_final = c_mixup(\n        X_train_clipped, \n        y_train_clipped, \n        alpha=c_mixup_alpha, \n        sigma=c_mixup_sigma,\n        augment_factor=c_mixup_factor\n    )\n    print(f\"C-Mixup applied: {X_train_clipped.shape[0]} -> {X_train_final.shape[0]} samples\")\nelse:\n    X_train_final = X_train_clipped\n    y_train_final = y_train_clipped\n    print(\"No augmentation\")\n\nX_val_final = X_val_clipped\ny_val_final = y_val_clipped\n\n\n# ============================================\n# Create DataLoaders\n# ============================================\ng = torch.Generator()\ng.manual_seed(SEED)\n\ntrain_dataset = TensorDataset(\n    torch.tensor(X_train_final, dtype=torch.float32), \n    torch.tensor(y_train_final, dtype=torch.float32)\n)\nval_dataset = TensorDataset(\n    torch.tensor(X_val_final, dtype=torch.float32), \n    torch.tensor(y_val_final, dtype=torch.float32)\n)\n\ntrain_loader = DataLoader(train_dataset, batch_size=params['batch_size'], \n                         shuffle=True, pin_memory=True, generator=g)\nval_loader = DataLoader(val_dataset, batch_size=params['batch_size'], \n                       shuffle=False, pin_memory=True)\n\n\n# ============================================\n# Initialize Model (Unified Structure)\n# ============================================\nprint(\"\\n\" + \"=\"*60)\nprint(\"MODEL INITIALIZATION\")\nprint(\"=\"*60)\n\n# Always use unified ResNetModel\nmodel = ResNetModel(\n    input_size=X_train_final.shape[1],\n    d=params['d'],\n    n_encoder_blocks=params['n_blocks'],\n    n_additional_blocks=params['n_additional_blocks'],\n    hidden_factor=params['hidden_factor'],\n    dropout_rate=params['dropout_rate']\n)\n\ntotal_blocks = params['n_blocks'] + params['n_additional_blocks']\nprint(f\"Model structure: {params['n_blocks']} encoder blocks + {params['n_additional_blocks']} additional blocks = {total_blocks} total\")\n\n# Load DAE pretrained weights if enabled\nif params['use_dae'] and dae_state is not None:\n    num_loaded = model.load_dae_encoder_weights(dae_state, freeze_encoder=params['freeze_dae'])\n    print(f\"\\nLoaded {num_loaded} DAE encoder parameters\")\n    print(f\"  - Encoder blocks: {params['n_blocks']} blocks (pretrained from DAE)\")\n    print(f\"  - Additional blocks: {params['n_additional_blocks']} blocks (randomly initialized)\")\n    \n    if params['freeze_dae']:\n        print(\"  - DAE encoder weights are FROZEN\")\n    else:\n        print(\"  - DAE encoder weights will be FINE-TUNED\")\nelse:\n    print(f\"\\nAll {total_blocks} blocks randomly initialized (no DAE pretraining)\")\n\nmodel = model.to(device)\nprint(f\"\\nModel moved to {device}\")\n\n\n# ============================================\n# Initialize Training Components\n# ============================================\n# EMA\nuse_ema = params['use_ema']\nema = EMA(model, decay=params['ema_decay']) if use_ema else None\nif use_ema:\n    print(f\"EMA enabled with decay={params['ema_decay']}\")\n\n# Loss function\nloss_map = {\n    'mse': nn.MSELoss(), \n    'mae': nn.L1Loss(), \n    'smooth_l1': nn.SmoothL1Loss(), \n    'huber': nn.HuberLoss()\n}\ncriterion = loss_map[params['loss_function']]\nprint(f\"Loss function: {params['loss_function']}\")\n\n# Optimizer\noptimizer_name = params['optimizer']\nis_schedulefree = optimizer_name.endswith('_schedulefree')\nif optimizer_name == 'adamw_schedulefree':\n    optimizer = AdamWScheduleFree(model.parameters(), lr=params['learning_rate'], \n                                 weight_decay=params['weight_decay'])\nelif optimizer_name == 'radam_schedulefree':\n    optimizer = RAdamScheduleFree(model.parameters(), lr=params['learning_rate'], \n                                 weight_decay=params['weight_decay'])\nelif optimizer_name == 'adamw':\n    optimizer = optim.AdamW(model.parameters(), lr=params['learning_rate'], \n                           weight_decay=params['weight_decay'])\nelse:\n    raise ValueError(f\"Unknown optimizer: {optimizer_name}\")\nprint(f\"Optimizer: {optimizer_name}\")\n\n# Mixed precision training\nuse_amp = torch.cuda.is_available()\nscaler = GradScaler('cuda') if use_amp else None\nif use_amp:\n    print(\"Mixed precision training enabled\")\n\n\n# ============================================\n# Training Loop\n# ============================================\nprint(\"\\n\" + \"=\"*60)\nprint(\"TRAINING\")\nprint(\"=\"*60)\n\nbest_val_rmse = float('inf')\nbest_model_state = None\nbest_ema_shadow = None\npatience_counter = 0\n\nfor epoch in range(epochs):\n    # Training mode\n    if is_schedulefree:\n        optimizer.train()\n    \n    model.train()\n    train_loss = 0\n    \n    for X_batch, y_batch in train_loader:\n        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n        \n        optimizer.zero_grad()\n        \n        if use_amp:\n            with autocast('cuda'):\n                outputs = model(X_batch)\n                loss = criterion(outputs.squeeze(-1), y_batch)\n            \n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            outputs = model(X_batch)\n            loss = criterion(outputs.squeeze(-1), y_batch)\n            loss.backward()\n            optimizer.step()\n        \n        train_loss += loss.item() * X_batch.size(0)\n        \n        if ema is not None:\n            ema.update()\n    \n    train_loss /= len(train_dataset)\n    \n    # Evaluation mode\n    if is_schedulefree:\n        optimizer.eval()\n    \n    if ema is not None:\n        ema.apply_shadow()\n    \n    model.eval()\n    \n    # Validation\n    val_predictions = []\n    val_targets = []\n    \n    with torch.no_grad():\n        for X_batch, y_batch in val_loader:\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            \n            if use_amp:\n                with autocast('cuda'):\n                    outputs = model(X_batch)\n            else:\n                outputs = model(X_batch)\n            \n            val_predictions.extend(outputs.squeeze(-1).cpu().numpy())\n            val_targets.extend(y_batch.cpu().numpy())\n    \n    if ema is not None:\n        ema.restore()\n    \n    # Calculate RMSE in original scale\n    val_predictions_unclipped = inverse_smooth_clip(np.array(val_predictions), clip_val=clip_val)\n    val_targets_unclipped = inverse_smooth_clip(np.array(val_targets), clip_val=clip_val)\n    \n    val_predictions_original = scaler_y.inverse_transform(val_predictions_unclipped.reshape(-1, 1)).flatten()\n    val_targets_original = scaler_y.inverse_transform(val_targets_unclipped.reshape(-1, 1)).flatten()\n    \n    val_rmse = np.sqrt(np.mean((val_predictions_original - val_targets_original)**2))\n    \n    # Print progress every 10 epochs\n    if (epoch + 1) % 10 == 0:\n        print(f\"Epoch {epoch + 1}/{epochs} - train_loss: {train_loss:.6f}, val_RMSE: {val_rmse:.4f} (best: {best_val_rmse:.4f})\")\n    \n    # Early stopping\n    if val_rmse < best_val_rmse:\n        best_val_rmse = val_rmse\n        best_model_state = copy.deepcopy(model.state_dict())\n        if ema is not None:\n            best_ema_shadow = copy.deepcopy(ema.shadow)\n        patience_counter = 0\n    else:\n        patience_counter += 1\n    \n    if patience_counter >= early_stopping_patience:\n        print(f\"\\nEarly stopping at epoch {epoch + 1}\")\n        break\n\nprint(f\"\\n{'='*60}\")\nprint(f\"TRAINING COMPLETE\")\nprint(f\"Best Validation RMSE: {best_val_rmse:.4f}\")\nprint(f\"{'='*60}\")\n\n\n# ============================================\n# Load best model and make predictions\n# ============================================\nprint(\"\\n\" + \"=\"*60)\nprint(\"MAKING PREDICTIONS\")\nprint(\"=\"*60)\n\nmodel.load_state_dict(best_model_state)\nif ema is not None and best_ema_shadow is not None:\n    # Apply EMA shadow for inference\n    for name, param in model.named_parameters():\n        if name in best_ema_shadow:\n            param.data = best_ema_shadow[name]\n\nmodel.eval()\ntest_tensor = torch.tensor(X_test_clipped, dtype=torch.float32).to(device)\n\nwith torch.no_grad():\n    if use_amp:\n        with autocast('cuda'):\n            predictions_clipped = model(test_tensor).squeeze().cpu().numpy()\n    else:\n        predictions_clipped = model(test_tensor).squeeze().cpu().numpy()\n    \n    # Inverse smooth clipping\n    predictions_unclipped = inverse_smooth_clip(predictions_clipped, clip_val=clip_val)\n    \n    # Inverse scaling\n    predictions = scaler_y.inverse_transform(predictions_unclipped.reshape(-1, 1)).flatten()\n\n# Save submission\nsubmission = pd.DataFrame({\n    \"id\": range(1455, 1455 + len(predictions)), \n    \"DIC\": predictions\n})\nsubmission_filename = f\"submission_resnet_dae_unified.csv\"\nsubmission.to_csv(submission_filename, index=False)\n\nprint(f\"Saved: {submission_filename}\")\nprint(f\"{'='*60}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# name: 坂田煌翔\n",
    "# student_id: 62408940"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7941427,
     "sourceId": 49552,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}